diff -Naur linux_org/drivers/net/ethernet/aspeed/ast_ether.c linux/drivers/net/ethernet/aspeed/ast_ether.c
--- linux_org/drivers/net/ethernet/aspeed/ast_ether.c	1970-01-01 08:00:00.000000000 +0800
+++ linux/drivers/net/ethernet/aspeed/ast_ether.c	2019-09-16 15:03:50.722159597 +0800
@@ -0,0 +1,1858 @@
+/*
+ * drivers/net/ast_ether.c - AST2050/AST2100/AST2150/AST2200 ethernet MAC driver
+ */
+
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/proc_fs.h>
+#include <asm/bitops.h>
+#include <asm/io.h>
+#include <linux/dma-mapping.h>
+#include <linux/errno.h>
+#include <linux/delay.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/crc32.h>
+#include <linux/ethtool.h>
+#include <linux/mii.h>
+#include <linux/rtnetlink.h>
+#include <net/ip.h>
+
+#include "ast_ether.h"
+
+#if (AST_ETHER_MAX_NUM == 4)
+const unsigned long ast_ether_phys_base[AST_ETHER_MAX_NUM] = { AST_ETHER_REG_BASE1, AST_ETHER_REG_BASE2,
+                                                               AST_ETHER_REG_BASE3, AST_ETHER_REG_BASE4 };
+const unsigned long ast_ether_irq[AST_ETHER_MAX_NUM] = { AST_ETHER_IRQ1, AST_ETHER_IRQ2,
+                                                         AST_ETHER_IRQ3, AST_ETHER_IRQ4 };
+#elif (AST_ETHER_MAX_NUM == 3)
+const unsigned long ast_ether_phys_base[AST_ETHER_MAX_NUM] = { AST_ETHER_REG_BASE1, AST_ETHER_REG_BASE2, 
+                                                               AST_ETHER_REG_BASE3 };
+const unsigned long ast_ether_irq[AST_ETHER_MAX_NUM] = { AST_ETHER_IRQ1, AST_ETHER_IRQ2, 
+                                                         AST_ETHER_IRQ3 };
+#elif (AST_ETHER_MAX_NUM == 2)
+const unsigned long ast_ether_phys_base[AST_ETHER_MAX_NUM] = {AST_ETHER_REG_BASE1, AST_ETHER_REG_BASE2};
+const unsigned long ast_ether_irq[AST_ETHER_MAX_NUM] = {AST_ETHER_IRQ1, AST_ETHER_IRQ2};
+#elif (AST_ETHER_MAX_NUM == 1)
+const unsigned long ast_ether_phys_base[AST_ETHER_MAX_NUM] = {AST_ETHER_REG_BASE1};
+const unsigned long ast_ether_irq[AST_ETHER_MAX_NUM] = {AST_ETHER_IRQ1};
+#else
+    #error "Not Supported SOC!"
+#endif
+
+//RTL8211F has display issue on duplex,here use a way like aspeed sdk 4.06 which use static value to store status
+static unsigned int ast_ether_duplex[AST_ETHER_MAX_NUM];
+
+static struct net_device *ast_ether_netdev[AST_ETHER_MAX_NUM];
+
+extern unsigned long enetaddr[][6];
+#ifdef BROADCAST_BLACKLIST
+static struct ast_bc ast_ether_bc[AST_ETHER_MAX_NUM];
+#endif
+static void ast_ether_free_rx_buf(struct net_device *dev);
+//int phy_ad = 0 ;
+
+static void ast_ether_get_hardware_addr(struct net_device* dev)
+{
+	struct ast_ether_priv *priv;
+	priv = netdev_priv(dev);
+
+	memcpy(dev->dev_addr, enetaddr[priv->idx], ETH_ALEN);
+}
+
+static void ast_ether_phy_rw_waiting(unsigned int ioaddr)
+{
+	int count;
+
+	count = 0;
+	while (inl(ioaddr + AST_ETHER_PHYCR) & (PHYCR_READ | PHYCR_WRITE)) {
+		udelay(1);
+		count ++;
+		if (count > 1000000)
+			break;
+	}
+}
+
+
+/* Reads a register from the MII Management serial interface */
+static u16 ast_ether_phy_read_register(struct net_device *dev, u8 phyaddr, u8 phyreg)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	unsigned int ioaddr = dev->base_addr;
+	u32 reg_val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->mii_lock, flags);
+	
+	reg_val = inl(ioaddr + AST_ETHER_PHYCR);
+
+	reg_val &= ~(PHYCR_WRITE | PHYCR_READ | PHYCR_REGAD_MASK | PHYCR_PHYAD_MASK); /* clear PHYAD, REGAD, MIIRD, MIIWR */
+	reg_val |= (phyaddr << PHYCR_PHYAD_SHIFT) & PHYCR_PHYAD_MASK;
+	reg_val |= (phyreg << PHYCR_REGAD_SHIFT) & PHYCR_REGAD_MASK;
+	reg_val |= PHYCR_READ;
+	
+	outl(reg_val, ioaddr + AST_ETHER_PHYCR);
+	
+	ast_ether_phy_rw_waiting(ioaddr);
+
+	reg_val = inl(ioaddr + AST_ETHER_PHYDATA) >> 16;
+
+	spin_unlock_irqrestore(&priv->mii_lock, flags);
+
+	return (u16)reg_val;
+}
+
+/* Writes a register to the MII Management serial interface */
+static void ast_ether_phy_write_register(struct net_device *dev, u8 phyaddr, u8 phyreg, u16 phydata)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	unsigned int ioaddr = dev->base_addr;
+	u32 reg_val;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->mii_lock, flags);
+
+	reg_val = inl(ioaddr + AST_ETHER_PHYCR);
+
+	reg_val &= ~(PHYCR_WRITE | PHYCR_READ | PHYCR_REGAD_MASK | PHYCR_PHYAD_MASK); /* clear PHYAD, REGAD, MIIRD, MIIWR */
+	reg_val |= (phyaddr << PHYCR_PHYAD_SHIFT) & PHYCR_PHYAD_MASK;
+	reg_val |= (phyreg << PHYCR_REGAD_SHIFT) & PHYCR_REGAD_MASK;
+	reg_val |= PHYCR_WRITE;
+
+	outl(phydata, ioaddr + AST_ETHER_PHYDATA);
+	outl(reg_val, ioaddr + AST_ETHER_PHYCR);
+
+	ast_ether_phy_rw_waiting(ioaddr);
+
+	spin_unlock_irqrestore(&priv->mii_lock, flags);
+}
+
+static void ast_ether_enable_expand_regs_and_clk(struct net_device* dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	u32 reg_val = 0x00;
+
+	switch (priv->phy_oui) 
+	{
+		case MARVELL_88E1111_OUI:
+		case BROADCOM_BCM5221_OUI:
+		case MICREL_KSZ80X1_OUI:
+		case REALTEK_RTL82X1X_OUI:
+			break;
+		case BROADCOM_BCM5241_OUI:
+			if(priv->phy_model != BCM54610_MODEL_NAME)	/* OUI of BCM54610 is also 0x0050EF,
+														it need enable expand reg and CLK125 */
+				break;
+		case BROADCOM_BCM5421_OUI:
+		case BROADCOM_BCM5461_OUI:
+		case BROADCOM_BCM54612E_OUI:
+			/* enable expand reg and CLK125 */
+			ast_ether_phy_write_register(dev, priv->phy_addr, 0x17, 0xd34);
+			reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, 0x15);
+			reg_val |= 0x02;
+			ast_ether_phy_write_register(dev, priv->phy_addr, 0x15, reg_val);
+			ast_ether_phy_write_register(dev, priv->phy_addr, 0x17, 0x0);
+			ast_ether_phy_write_register(dev, priv->phy_addr, 0x1C, 0x8c00);
+			ast_ether_phy_write_register(dev, priv->phy_addr, 0x18, 0xf0e7);
+			break;
+		default:
+			priv->phy_oui = 0; /* not supported PHY or NC-SI */
+			break;
+	}
+
+	return;
+}
+
+/* read OUI and Model of PHY */
+static void ast_ether_read_phy_id(struct net_device* dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	u32 reg_val;
+	int i, ret1, ret2;
+
+	for(i = 0 ; i < 32 ; i++){
+		ret1 = ast_ether_phy_read_register(dev, i, PHY_COM_REG_ADDR_ID_HI);
+		ret2 = ast_ether_phy_read_register(dev, i, PHY_COM_REG_ADDR_ID_LO);
+		if( ret1 != 0xffff && ret2 != 0xffff ){
+			priv->phy_addr = i;
+			break;
+		}
+	}
+
+	/* OUI[23:22] are not represented in PHY ID registers */
+	reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_ID_HI);
+	priv->phy_oui = (reg_val & 0xFFFF) << 6; /* OUI[21:6] in ID_HI[15:0] */
+
+	reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_ID_LO);
+	priv->phy_oui |= (reg_val & 0xFFFF) >> 10; /* OUI[5:0] in ID_LO[15:10] */
+
+	priv->phy_model = (reg_val & 0x03F0) >> 4; /* MODEL[5:0] in ID_LO[9:4] */
+
+	priv->phy_rev = (reg_val & 0x000F); /* Revision[5:0] in ID_LO[3:0] */
+
+	ast_ether_enable_expand_regs_and_clk(dev);
+}
+
+/**
+ * ast_mii_check_gmii_support (origin from mii_check_gmii_support) - check if the MII supports Gb interfaces 
+ * @dev: the net interface
+ */  
+int ast_mii_check_gmii_support(struct net_device *dev)                                                                                                     
+{        
+    struct ast_ether_priv *priv = netdev_priv(dev);
+    uint32_t reg = 0;
+    reg = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMSR);
+
+    if (reg & BMSR_ESTATEN) {
+        reg = ast_ether_phy_read_register(dev, priv->phy_addr, MII_ESTATUS);
+        if (reg & (ESTATUS_1000_TFULL | ESTATUS_1000_THALF))
+            return 1; 
+    }
+
+    return 0;
+}  
+
+/* Configures the PHY to restart Auto-Negotiation. */
+void ast_ether_phy_restart_auto_neg(struct net_device* dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	u16 reg_val;
+
+	/* restart auto-negotiation */
+	reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_CONTROL);
+	reg_val |= PHY_COM_REG_CONTROL_RE_AUTO;
+	ast_ether_phy_write_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_CONTROL, reg_val);
+
+	/* Waiting for complete Auto-Negotiation */
+	while ((ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_STATUS) & PHY_COM_REG_STATUS_AUTO_OK) == 0)
+		mdelay(2);
+}
+
+static void ast_ether_set_link_status(struct net_device* dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	unsigned int ioaddr = dev->base_addr;
+	unsigned int reg_val=0, duplex=0, speed=0;
+
+	if (priv->phy_oui != 0) {
+		reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_STATUS);
+		if (reg_val & PHY_COM_REG_STATUS_LINK) {
+            if (rtnl_trylock())
+            {
+				if(priv->link_state != 1)
+				{
+					netdev_link_up(dev);
+					priv->link_state = 1;
+				}
+                rtnl_unlock();
+            }
+            else
+            {
+				if(priv->link_state != 1)
+				{
+					netdev_link_up(dev);
+					priv->link_state = 1;
+				}
+            }
+			/* read speed and duplex from PHY */
+			switch (priv->phy_oui) {
+			case MARVELL_88E1111_OUI:
+				reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, MARVELL_88E1111_REG_ADDR_PHY_STATUS);
+				duplex = (reg_val & MARVELL_88E1111_REG_PHY_STATUS_DUPLEX_MASK) >> 13;
+				speed = (reg_val & MARVELL_88E1111_REG_PHY_STATUS_SPEED_MASK) >> 14;
+				break;
+			case BROADCOM_BCM5221_OUI:
+			case BROADCOM_BCM5241_OUI:
+				if(priv->phy_model != BCM54610_MODEL_NAME)
+				{
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, BROADCOM_BCM5221_REG_ADDR_AUX_CTRL_STAT);
+					duplex = (reg_val & BROADCOM_BCM5221_REG_AUX_CTRL_STAT_DEPLEX) ? PHY_DUPLEX_FULL : PHY_DUPLEX_HALF;
+					speed = (reg_val & BROADCOM_BCM5221_REG_AUX_CTRL_STAT_SPEED) ? PHY_SPEED_100M : PHY_SPEED_10M;
+					break;
+				}
+				else	/* for BCM54610 */
+				{
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, BROADCOM_BCM54610_REG_ADDR_AUX_CTRL_STAT);
+					switch(reg_val)
+						{
+							case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_FULL_1000: 
+							    duplex = PHY_DUPLEX_FULL; 
+							    speed = PHY_SPEED_1000M; 
+							    break; 
+							case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_HALF_1000: 
+							    duplex = PHY_DUPLEX_HALF; 
+							    speed = PHY_SPEED_1000M; 
+							    break; 
+							case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_FULL_100: 
+							    duplex = PHY_DUPLEX_FULL; 
+							    speed = PHY_SPEED_100M; 
+							    break; 
+							case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_HALF_100: 
+							    duplex = PHY_DUPLEX_HALF; 
+							    speed = PHY_SPEED_100M; 
+							    break; 
+						    case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_FULL_10: 
+							    duplex = PHY_DUPLEX_FULL; 
+							    speed = PHY_SPEED_10M; 
+							    break; 
+                           case BROADCOM_BCM54610_REG_AUX_CTRL_STAT_HALF_10: 
+							    duplex = PHY_DUPLEX_HALF; 
+							    speed = PHY_SPEED_10M; 
+							    break; 
+							default: 
+							    duplex = PHY_DUPLEX_FULL; 
+							    speed = PHY_SPEED_100M; 
+							    break;
+						}
+				}
+			case BROADCOM_BCM5461_OUI:
+			case BROADCOM_BCM54612E_OUI:
+			case BROADCOM_BCM5421_OUI:
+            	reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, 0x1C); 
+            	if ((reg_val & 0x7c00) != 0x2000) 
+            	{ 
+            		ast_ether_phy_write_register(dev, priv->phy_addr, 0x1C, 0x2000); 
+            		reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, 0x1C); 
+            	} 
+            	if ((reg_val & 0x0080) != 0) 
+            		duplex = PHY_DUPLEX_HALF; 
+            	else 
+            		duplex = PHY_DUPLEX_FULL; 
+
+            	if ((reg_val & 0x0018) == 0)  
+            		speed = PHY_SPEED_1000M; 
+            	else 
+            		if ((reg_val & 0x0018) == 0x0010)  
+            			speed = PHY_SPEED_10M; 
+            		else 
+            			speed = PHY_SPEED_100M; 
+            	break; 
+			case REALTEK_RTL82X1X_OUI:
+				switch (priv->phy_model) {
+				case 0x01:
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, PHY_COM_REG_ADDR_CONTROL);
+					duplex = (reg_val & PHY_COM_REG_CONTROL_DUPLEX) ? PHY_DUPLEX_FULL : PHY_DUPLEX_HALF;
+					speed = (reg_val & PHY_COM_REG_CONTROL_SPEED) ? PHY_SPEED_100M : PHY_SPEED_10M;
+					break;
+				case 0x11:
+					if(priv->phy_rev == 0x06) {
+						reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, REALTEK_RTL8211F_REG_ADDR_PHY_STAT);
+						duplex = (reg_val & REALTEK_RTL8211F_REG_ADDR_PHY_STS_DEPLEX) ? PHY_DUPLEX_FULL : PHY_DUPLEX_HALF;
+						speed = (reg_val & REALTEK_RTL8211F_REG_ADDR_PHY_STS_SPEED_MASK) >> REALTEK_RTL8211F_REG_ADDR_PHY_STS_SPEED_SHIFT;
+					} else {
+						reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, REALTEK_RTL8211B_REG_ADDR_PHY_STAT);
+						duplex = (reg_val & REALTEK_RTL8211B_REG_ADDR_PHY_STS_DEPLEX) ? PHY_DUPLEX_FULL : PHY_DUPLEX_HALF;
+						speed = (reg_val & REALTEK_RTL8211B_REG_ADDR_PHY_STS_SPEED_MASK) >> REALTEK_RTL8211B_REG_ADDR_PHY_STS_SPEED_SHIFT;
+					}
+					break;
+				default:
+					speed = PHY_SPEED_100M;
+					duplex = 1;
+				}
+				break;
+			case MICREL_KSZ80X1_OUI:
+				switch (priv->phy_model) {
+				case 0x11://8041
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, MICREL_KSZ8041_REG_STATUS);
+					reg_val = (reg_val & MICREL_KSZ8041_REG_STATUS_MASK) >> MICREL_KSZ8041_REG_STATUS_SHIFT;
+					switch (reg_val) {
+					case MICREL_KSZ8041_REG_STATUS_HALF_10:
+						duplex = PHY_DUPLEX_HALF;
+						speed = PHY_SPEED_10M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_HALF_100:
+						duplex = PHY_DUPLEX_HALF;
+						speed = PHY_SPEED_100M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_FULL_10:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_10M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_FULL_100:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_100M;
+						break;
+					default:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_100M;
+						break;
+					}
+					break;
+				case 0x15://8031
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, MICREL_KSZ8031_REG_STATUS);
+					reg_val = reg_val & MICREL_KSZ8031_REG_STATUS_MASK;
+					switch (reg_val) {
+					case MICREL_KSZ8041_REG_STATUS_HALF_10:
+						duplex = PHY_DUPLEX_HALF;
+						speed = PHY_SPEED_10M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_HALF_100:
+						duplex = PHY_DUPLEX_HALF;
+						speed = PHY_SPEED_100M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_FULL_10:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_10M;
+						break;
+					case MICREL_KSZ8041_REG_STATUS_FULL_100:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_100M;
+						break;
+					default:
+						duplex = PHY_DUPLEX_FULL;
+						speed = PHY_SPEED_100M;
+						break;
+					}
+					break;
+				case 0x22://9031
+					reg_val = ast_ether_phy_read_register(dev, priv->phy_addr, MICREL_KSZ9031_REG_STATUS);
+					if(reg_val & (1 << 6)) 
+						speed = PHY_SPEED_1000M;
+					else if(reg_val & (1 << 5))
+						speed = PHY_SPEED_100M;
+					else 
+						speed = PHY_SPEED_10M;
+					
+					if(reg_val & (1 << 3))
+						duplex = PHY_DUPLEX_FULL;
+					else
+						duplex = PHY_DUPLEX_HALF;
+					break;
+				default:
+					reg_val = 0;
+					break;
+				}
+				break;
+			default:
+				speed = PHY_SPEED_100M;
+				duplex = 1;
+				break;
+			}
+			netif_carrier_on(dev);
+		} else { /* link is down */
+            if (rtnl_trylock())
+            {
+				if(priv->link_state != 0)
+				{
+					netdev_link_down(dev);
+					priv->link_state = 0;
+				}
+                rtnl_unlock();
+            }
+            else
+            {
+				if(priv->link_state != 0)
+				{
+					netdev_link_down(dev);
+					priv->link_state = 0;
+				}
+            }
+			/* default setting: 100M, duplex */
+			speed = PHY_SPEED_100M;
+			duplex = 1;
+			netif_carrier_off(dev);
+		}
+	} else { /* not support PHY of NC-SI */
+		/* default setting: 100M, duplex */
+		speed = PHY_SPEED_100M;
+		duplex = 1;
+		//netif_carrier_on(dev);
+	}
+
+	if (speed == priv->old_speed && duplex == priv->old_duplex)
+	{
+		return;
+	}
+	
+	priv->old_speed = speed;
+	priv->old_duplex = duplex;
+	reg_val = inl(ioaddr + AST_ETHER_MACCR);
+
+	/* set speed */
+	if (speed == PHY_SPEED_1000M) { /* 1000 Mbps */
+		priv->maccr |= (MACCR_GMAC_MODE | MACCR_SPEED_100);
+		reg_val |= (MACCR_GMAC_MODE | MACCR_SPEED_100);
+	} else { /* 10/100 Mbps */
+		reg_val &= ~(MACCR_GMAC_MODE | MACCR_SPEED_100);
+		priv->maccr &= ~(MACCR_GMAC_MODE | MACCR_SPEED_100);
+
+		if (speed == PHY_SPEED_100M) {
+			reg_val |= MACCR_SPEED_100;
+			priv->maccr |= MACCR_SPEED_100;
+		}
+	}
+
+	/* set duplex */
+	ast_ether_duplex[priv->idx] = duplex;
+	if (duplex == PHY_DUPLEX_FULL) {
+		priv->maccr |= MACCR_FULLDUP;
+		reg_val |= MACCR_FULLDUP;
+	} else {
+		priv->maccr &= ~MACCR_FULLDUP;
+		reg_val &= ~MACCR_FULLDUP;
+	}
+
+	outl(reg_val, ioaddr + AST_ETHER_MACCR);
+}
+
+#ifdef BROADCAST_BLACKLIST
+static void ast_ether_bc_checker(unsigned long data)
+{
+	struct net_device *dev;
+	struct ast_ether_priv *priv;
+	unsigned int reg_value ;
+	unsigned int ioaddr;
+
+	dev = (struct net_device *) data;
+	ioaddr = dev->base_addr;
+	priv = netdev_priv(dev);
+
+	if( ast_ether_bc[priv->idx].bc_ctr ){
+		ast_ether_bc[priv->idx].bc_count = 0 ;  
+		ast_ether_bc[priv->idx].bc_ctr = 0 ;
+		reg_value = inl(ioaddr + AST_ETHER_IER);
+		reg_value |= (ISR_RPKT2B) ;
+		outl(reg_value, ioaddr + AST_ETHER_IER);
+	}
+	else
+		ast_ether_bc[priv->idx].bc_count = 0 ;
+
+	ast_ether_bc[priv->idx].timer.expires = jiffies + (AST_BC_CHECK_INTERVAL * HZ);
+	add_timer(&ast_ether_bc[priv->idx].timer);
+}
+#endif
+
+static void ast_ether_phy_status_checker(unsigned long data)
+{
+	struct net_device *dev;
+	struct ast_ether_priv *priv;
+
+	dev = (struct net_device *) data;
+	priv = netdev_priv(dev);
+
+	ast_ether_set_link_status(dev);
+
+	priv->timer.expires = jiffies + (AST_PHY_STATUS_CHECK_INTERVAL * HZ);
+	add_timer(&priv->timer);
+}
+
+/* allocates memory for Tx/Rx descriptors, we use ring structure(AST2100 does not support chain structure) */
+static void ast_ether_alloc_descriptor(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+
+	/* allocate Rx descriptors */
+	priv->rx_desc = dma_alloc_coherent(NULL, sizeof(struct ast_eth_desc) * RX_DES_NUM, &priv->rx_desc_dma, GFP_KERNEL);
+	if (priv->rx_desc == NULL) {
+		printk(KERN_ERR "%s: allocate Rx descriptor failed.\n", dev->name);
+	}
+	memset(priv->rx_desc, 0, sizeof(struct ast_eth_desc) * RX_DES_NUM);
+
+	/* allocate Tx descriptors */
+	priv->tx_desc = dma_alloc_coherent(NULL, sizeof(struct ast_eth_desc) * TX_DES_NUM, &priv->tx_desc_dma, GFP_KERNEL);
+	if (priv->tx_desc == NULL) {
+		printk(KERN_ERR "%s: allocate Tx descriptor failed.\n", dev->name);
+	}
+	memset(priv->tx_desc, 0, sizeof(struct ast_eth_desc) * TX_DES_NUM);
+}
+
+static void ast_ether_init_descriptor(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	int i;
+
+	/* initializes Rx descriptors */
+	priv->cur_rx = 0;
+	priv->dirty_rx = 0;
+	/* allocate Rx buffers */
+	for (i = 0; i < RX_DES_NUM; i ++) {
+        struct sk_buff *rx_skbuff = priv->rx_skbuff[i];
+        if (rx_skbuff == NULL) {
+            if (!(rx_skbuff = priv->rx_skbuff[i] = dev_alloc_skb (RX_BUF_SIZE + 16))) {
+                printk(KERN_ERR "%s: allocate Rx buffer failed.\n", dev->name);
+                ast_ether_free_rx_buf(dev);
+                return;
+            }
+            rx_skbuff->dev = dev; /* Mark as being used by this device. */
+            skb_reserve(rx_skbuff, NET_IP_ALIGN); /* 16 byte align the IP header. */
+        }
+        
+        rmb();
+		priv->rx_skb_dma[i] = dma_map_single(NULL, rx_skbuff->data, RX_BUF_SIZE, DMA_FROM_DEVICE);
+		priv->rx_desc[i].buffer = priv->rx_skb_dma[i];
+        wmb();
+        priv->rx_desc[i].status &= ~RX_DESC_RXPKT_RDY; /* haredware owns descriptor */
+	}
+
+	priv->rx_desc[RX_DES_NUM - 1].status |= RX_DESC_EDORR; /* last descriptor */
+
+	/* initializes Tx descriptors */
+	priv->cur_tx = 0;
+	priv->dirty_tx = 0;
+	for (i = 0; i < TX_DES_NUM; i ++) {
+		priv->tx_desc[i].status &= ~TX_DESC_TXDMA_OWN; /* software owns descriptor */
+		priv->tx_skbuff[i] = NULL;
+		priv->tx_skb_dma[i] = 0;
+	}
+	priv->tx_desc[TX_DES_NUM - 1].status |= TX_DESC_EDOTR; /* last descriptor */
+}
+
+static void ast_ether_up(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	unsigned int ioaddr = dev->base_addr;
+	unsigned int reg_value;
+	unsigned int rfifo_rsize;
+	unsigned int tfifo_rsize;
+	u32 hardware_addr;
+	int i;
+
+	/* software reset */
+	outl(MACCR_SW_RST, ioaddr + AST_ETHER_MACCR);
+
+	/* wait SW_RST bit to be auto cleared */
+	while ((inl(ioaddr + AST_ETHER_MACCR) & MACCR_SW_RST) != 0)
+		mdelay(10);
+
+	outl(0, ioaddr + AST_ETHER_IER); /* Disable all interrupts */
+
+	/* reset Rx descriptors */
+	priv->cur_rx = 0;
+	priv->dirty_rx = 0;
+	for (i = 0; i < RX_DES_NUM; i ++) {
+		priv->rx_desc[i].status &= ~RX_DESC_RXPKT_RDY; /* haredware owns descriptor */
+	}
+
+	/* reset Tx descriptors */
+	priv->cur_tx = 0;
+	priv->dirty_tx = 0;
+	for (i = 0; i < TX_DES_NUM; i ++) {
+		priv->tx_desc[i].status &= ~TX_DESC_TXDMA_OWN; /* software owns descriptor */
+		priv->tx_skbuff[i] = NULL;
+		priv->tx_skb_dma[i] = 0;
+	}
+
+	/* set the MAC address */
+	hardware_addr = ((u32)dev->dev_addr[0]) << 8 | (u32)dev->dev_addr[1];
+	outl(hardware_addr, ioaddr + AST_ETHER_MAC_MADR);
+
+	hardware_addr = 0;
+	for (i = 0; i < 4; i ++)
+		hardware_addr |= ((u32)(dev->dev_addr[i + 2])) << (8 * (4 - 1 - i));
+	outl(hardware_addr, ioaddr + AST_ETHER_MAC_LADR);
+
+	/* hardware works with bus address */
+	outl(priv->rx_desc_dma, ioaddr + AST_ETHER_RXR_BADR);
+	outl(priv->tx_desc_dma, ioaddr + AST_ETHER_TXR_BADR);
+
+	/* set interrupt timer */
+	reg_value = (((1 << ITCR_TXINT_THR_SHIFT) & ITCR_TXINT_THR_MASK) |
+				((0 << ITCR_TXINT_CNT_SHIFT) & ITCR_TXINT_CNT_MASK) |
+				((1 << ITCR_RXINT_THR_SHIFT) & ITCR_RXINT_THR_MASK) |
+				((0 << ITCR_RXINT_CNT_SHIFT) & ITCR_RXINT_CNT_MASK));
+	outl(reg_value, ioaddr + AST_ETHER_ITC);
+
+	/* set automatic polling timer */
+	reg_value = (((0 << APTC_TXPOLL_CNT_SHIFT) & APTC_TXPOLL_CNT_MASK) | 
+				((1 << APTC_RXPOLL_CNT_SHIFT) & APTC_RXPOLL_CNT_MASK));
+	outl(reg_value, ioaddr + AST_ETHER_APTC);
+	
+	/* set Tx/Rx descriptor size, max size of DMA burst, Rx FIOF hish/low threshold */
+	outl(0x00022F72, ioaddr + AST_ETHER_DBLAC);
+	/*Flow control enable*/
+	reg_value=inl(ioaddr + AST_ETHER_FCR);
+	reg_value |= 0xffff0805;
+	outl(reg_value, ioaddr + AST_ETHER_FCR);
+
+	/* read hardware FIFO size */
+	reg_value = inl(ioaddr + AST_ETHER_FEAR);
+	rfifo_rsize = (reg_value & FEAR_RFIFO_RSIZE_MASK) >> FEAR_RFIFO_RSIZE_SHIFT;
+	tfifo_rsize = (reg_value & FEAR_TFIFO_RSIZE_MASK) >> FEAR_TFIFO_RSIZE_SHIFT;
+
+	/* set Tx/Rx FIFO size and Tx priority threshold */
+	reg_value = inl(ioaddr + AST_ETHER_TPAFCR);
+	reg_value &= ~(FPAFCR_TFIFO_SIZE_MASK | FPAFCR_RFIFO_SIZE_MASK);
+	reg_value |= (tfifo_rsize << FPAFCR_TFIFO_SIZE_SHIFT);
+	reg_value |= (rfifo_rsize << FPAFCR_RFIFO_SIZE_SHIFT);
+	outl(reg_value, ioaddr + AST_ETHER_TPAFCR);
+
+	/* set rx buffer size */
+	outl(RX_BUF_SIZE & RBSR_MASK, ioaddr + AST_ETHER_RBSR);
+
+	/* enable interrupts */
+	reg_value = ISR_AHB_ERR | ISR_TPKT_LOST | ISR_TPKT2E | ISR_RPKT_LOST | ISR_RXBUF_UNAVA | ISR_RPKT2B;
+	if (priv->phy_oui != 0) {
+		if(priv->timer.function != NULL)
+			del_timer_sync(&priv->timer);
+		init_timer(&priv->timer);
+		priv->timer.data = (unsigned long) dev;
+		priv->timer.function = ast_ether_phy_status_checker;
+		priv->timer.expires = jiffies + (AST_PHY_STATUS_CHECK_INTERVAL * HZ);
+		add_timer(&priv->timer);
+	}
+	
+#ifdef BROADCAST_BLACKLIST
+	ast_ether_bc[priv->idx].bc_count = 0 ;	
+	ast_ether_bc[priv->idx].bc_ctr = 0 ;
+	ast_ether_bc[priv->idx].trans_busy_1 = 0 ; 
+	ast_ether_bc[priv->idx].trans_busy_2 = 0 ; 
+
+	init_timer(&ast_ether_bc[priv->idx].timer);
+	ast_ether_bc[priv->idx].timer.data = (unsigned long) dev;
+	ast_ether_bc[priv->idx].timer.function = ast_ether_bc_checker;
+	ast_ether_bc[priv->idx].timer.expires = jiffies + (AST_BC_CHECK_INTERVAL * HZ);
+	add_timer(&ast_ether_bc[priv->idx].timer);
+#endif
+	outl(reg_value, ioaddr + AST_ETHER_IER);
+
+	/* enable trans/recv, ... */
+	outl(priv->maccr, ioaddr + AST_ETHER_MACCR);
+}
+
+static void ast_ether_down(unsigned int ioaddr)
+{
+	outl(0, ioaddr + AST_ETHER_IER); /* Disables all interrupts */
+	outl(0, ioaddr + AST_ETHER_MACCR); /* Disables trans/recv, ... */
+}
+
+static int ast_ether_tx(struct sk_buff *skb, struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	volatile struct ast_eth_desc *cur_desc, *first;
+	int entry;
+	int length;
+	int nfrags, i;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	/* Note: the chip doesn't have auto-pad! */
+	length = skb->len;
+	if (length < ETH_ZLEN) {
+		if (skb_padto(skb, ETH_ZLEN) < 0) {
+			priv->stats.tx_dropped ++;
+			spin_unlock_irqrestore(&priv->lock, flags);
+			return 0;
+		}
+		length = ETH_ZLEN;
+	}
+
+        nfrags = skb_shinfo(skb)->nr_frags;
+	
+	/* Get header len and pad for non-fragmented packets */ 
+	length = skb_headlen(skb); 
+	if (nfrags == 0 && length < ETH_ZLEN) 
+		length = ETH_ZLEN; 
+
+	entry = priv->cur_tx & (TX_DES_NUM - 1);
+	cur_desc = first = &priv->tx_desc[entry];
+
+	if (cur_desc->status & TX_DESC_TXDMA_OWN) {
+		netif_stop_queue(dev);
+		priv->stats.tx_dropped ++;
+		spin_unlock_irqrestore(&priv->lock, flags);
+		return 1;
+	}
+
+	priv->tx_skbuff[entry] = skb;
+	priv->tx_skb_dma[entry] = dma_map_single(NULL, skb->data, length, DMA_TO_DEVICE);
+
+	cur_desc->buffer = priv->tx_skb_dma[entry];
+	cur_desc->status |= (length | TX_DESC_FTS);
+
+
+	/* Setup HW checksumming */
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		__be16 protocol = skb->protocol;
+
+		if (protocol == cpu_to_be16(ETH_P_IP)) {
+			u8 ip_proto = ip_hdr(skb)->protocol;
+			cur_desc->vlan |= TX_DESC_IPCS_EN;
+
+			if (ip_proto == IPPROTO_TCP) {
+				cur_desc->vlan |= TX_DESC_TCPCS_EN;
+			}
+			else if (ip_proto == IPPROTO_UDP) {
+				cur_desc->vlan |= TX_DESC_UDPCS_EN;
+			}
+		} 
+		else if (skb_checksum_help(skb)) {
+			priv->stats.tx_dropped ++;
+			spin_unlock_irqrestore(&priv->lock, flags);
+			return 0;
+		}
+	}
+	priv->cur_tx++;
+	entry = priv->cur_tx & (TX_DES_NUM - 1);
+
+	/* Add the fragments */ 
+	for (i = 0; i < nfrags; i++) { 
+		skb_frag_t *frag = &skb_shinfo(skb)->frags[i]; 
+
+		length = frag->size; 
+
+		/* Map it */ 
+		priv->tx_skb_dma[entry] = skb_frag_dma_map(NULL, frag, 0, length, DMA_TO_DEVICE); 
+
+		/* Setup descriptor */ 
+		priv->tx_skbuff[entry] = skb;
+		cur_desc = &priv->tx_desc[entry];
+		cur_desc->buffer = priv->tx_skb_dma[entry];
+		cur_desc->status |= length;
+		cur_desc->status |= TX_DESC_TXDMA_OWN;
+
+		/* 
+		 * The spec is unclear, whether these need to be in the 
+		 * first descriptor only or all of them. Gor now, do all 
+		 * of them. 
+		 */ 
+		cur_desc->vlan |= first->vlan & (TX_DESC_IPCS_EN | TX_DESC_TCPCS_EN | TX_DESC_UDPCS_EN); 
+
+		priv->cur_tx++;
+		entry = priv->cur_tx & (TX_DES_NUM - 1);
+	} 
+
+	/* Tag last fragment */ 
+	cur_desc->status |= TX_DESC_LTS;
+
+	/* 
+	 * Set the own bit on the first descriptor, this can cause the 
+	 * HW to transmit, it needs to be ordered after all previous 
+	 * stores. 
+	 */ 
+	wmb();
+	first->status |= TX_DESC_TXDMA_OWN;
+
+	dev->trans_start = jiffies;
+	outl(0xffffffff, dev->base_addr + AST_ETHER_TXPD); /* Trigger an Tx Poll demand */
+
+	if (priv->cur_tx - priv->dirty_tx >= TX_DES_NUM - (MAX_SKB_FRAGS + 1)){
+		netif_stop_queue(dev);
+	}
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+static void ast_ether_free_tx_buf(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	int entry;
+	unsigned long flags;
+
+	spin_lock_irqsave(&priv->lock, flags);
+
+	/* Free used tx sk_buffs */
+	while (priv->dirty_tx != priv->cur_tx) {
+		entry = priv->dirty_tx & (TX_DES_NUM - 1);
+		if (priv->tx_desc[entry].status & TX_DESC_TXDMA_OWN)
+			break;
+
+		if (priv->tx_desc[entry].status & TX_DESC_FTS) {
+			size_t length = skb_headlen(priv->tx_skbuff[entry]);
+			if (skb_shinfo(priv->tx_skbuff[entry])->nr_frags == 0 && length < ETH_ZLEN)
+				length = ETH_ZLEN;
+
+			dma_unmap_single(NULL, priv->tx_skb_dma[entry], length, DMA_TO_DEVICE);
+		} else
+			dma_unmap_page(NULL, priv->tx_skb_dma[entry], priv->tx_desc[entry].status & TX_DESC_TXBUF_SIZE, DMA_TO_DEVICE);
+
+		if(priv->tx_desc[entry].status & TX_DESC_LTS) {
+			priv->stats.tx_packets ++;
+			priv->stats.tx_bytes += priv->tx_skbuff[entry]->len; 
+			dev_kfree_skb_irq(priv->tx_skbuff[entry]);
+		}
+
+		/* Clear except end of ring bit */
+		priv->tx_desc[entry].status &= TX_DESC_EDOTR;
+		priv->tx_desc[entry].vlan = 0;
+		priv->tx_skbuff[entry] = NULL;
+		priv->tx_skb_dma[entry] = 0;
+		priv->dirty_tx ++;
+	}
+
+	if (netif_queue_stopped(dev) && (priv->cur_tx - priv->dirty_tx < TX_DES_NUM - (MAX_SKB_FRAGS + 1)))
+		netif_wake_queue(dev);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+}
+
+static void ast_ether_realloc_rx_buf(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	struct sk_buff *skb;
+	int entry;
+
+	/* Reallocate the Rx ring buffers. */
+	while (priv->dirty_rx != priv->cur_rx) {
+		entry = priv->dirty_rx & (RX_DES_NUM - 1);
+		if (priv->rx_skbuff[entry] == NULL) {
+			skb = dev_alloc_skb(RX_BUF_SIZE + 16);
+			priv->rx_skbuff[entry] = skb;
+			if (skb == NULL) {
+				printk(KERN_ERR "%s: reallocate Rx buffer failed.\n", dev->name);
+                ast_ether_free_rx_buf(dev);
+                return;
+			}
+
+			skb->dev = dev; /* Mark as being used by this device. */
+			skb_reserve(skb, NET_IP_ALIGN); /* 16 byte align the IP header. */
+
+			priv->rx_skb_dma[entry] = dma_map_single(NULL, skb->data, RX_BUF_SIZE, DMA_FROM_DEVICE);
+			priv->rx_desc[entry].buffer = priv->rx_skb_dma[entry];
+			wmb();
+			priv->rx_desc[entry].status &= RX_DESC_EDORR; /* clear all field except EDORR, return ownership to hardware */
+		}
+		priv->dirty_rx ++;
+	}
+}
+
+static void ast_ether_free_rx_buf(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	int i;
+
+	/* free all allocated skbuffs */
+    priv->cur_rx = 0;
+	priv->dirty_rx = 0;
+	for (i = 0; i < RX_DES_NUM; i++) {
+		priv->rx_desc[i].status = 0;
+		wmb();		/* Make sure adapter sees owner change */
+		if (priv->rx_skbuff[i]) {
+            dma_unmap_single(NULL, priv->rx_skb_dma[i], priv->rx_skbuff[i]->len, DMA_TO_DEVICE);
+            dev_kfree_skb_irq(priv->rx_skbuff[i]);
+
+		}
+		priv->rx_skbuff[i] = NULL;
+		priv->rx_skb_dma[i] = 0;
+	}
+}
+
+
+static inline void ast_ether_rx_csum(struct sk_buff *skb, struct ast_eth_desc *desc)
+{
+	u32 status = desc->vlan;
+	u32 protocol_type = status & RX_DESC_PROTL_TYPE_MASK;
+
+	///Checking IP protcol here allowing the invalid ICMP checksum packets hence check is removed
+	if (((protocol_type == RX_DESC_PROTL_TYPE_UDP) && !(status & RX_DESC_UDPCS_FAIL)) ||
+		((protocol_type == RX_DESC_PROTL_TYPE_TCP) && !(status & RX_DESC_TCPCS_FAIL)))
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+	else
+		skb->ip_summed = CHECKSUM_NONE;
+}
+
+static void ast_ether_rx(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	struct sk_buff *skb;
+	u32 status;
+	int pkt_len;
+	int has_error;
+	int has_first;
+	int entry;
+#ifdef BROADCAST_BLACKLIST
+	unsigned int ioaddr = dev->base_addr;
+	unsigned int reg_value;
+#endif
+
+	has_error = 0;
+	has_first = 0;
+
+	while ((priv->dirty_rx + RX_DES_NUM) != priv->cur_rx) {
+		entry = priv->cur_rx & (RX_DES_NUM - 1);
+		status = priv->rx_desc[entry].status;
+		if (!(status & RX_DESC_RXPKT_RDY)) /* owned by hardware */
+            break;
+
+		if ((status & RX_DESC_FRS)&&(status & RX_DESC_LRS)) { /* first frame of packet, check error */
+			if (status & RX_DESC_FIFO_FULL) {
+                priv->stats.rx_dropped++;
+            
+            }
+            else {
+				has_first = 1;
+
+				if (status & (RX_DESC_RX_ERR | RX_DESC_CRC_ERR | RX_DESC_FTL | RX_DESC_RUNT | RX_DESC_RX_ODD_NB | RX_DESC_IPCS_FAIL )) { /* There was an error. */
+					priv->stats.rx_errors ++;
+					has_error = 1;
+				}            	
+            }
+
+			if (status & RX_DESC_MULTICAST)
+				priv->stats.multicast ++;
+			
+#ifdef BROADCAST_BLACKLIST
+#ifndef CONFIG_ASTMAC100_NAPI
+			if ((status & RX_DESC_BROADCAST)||(status & RX_DESC_MULTICAST)){
+				if( !ast_ether_bc[priv->idx].bc_ctr ){
+					ast_ether_bc[priv->idx].bc_count++;
+					if (ast_ether_bc[priv->idx].bc_count >= 1000) {
+						reg_value = inl(ioaddr + AST_ETHER_IER);
+						reg_value &= ~(ISR_RPKT2B) ;
+						outl(reg_value, ioaddr + AST_ETHER_IER);
+						ast_ether_bc[priv->idx].bc_ctr = 1 ;
+					}
+				}
+			}
+#endif
+#endif
+		}
+
+		skb = priv->rx_skbuff[entry];
+		dma_unmap_single(NULL, priv->rx_skb_dma[entry], RX_BUF_SIZE, DMA_FROM_DEVICE);
+		priv->rx_skbuff[entry] = NULL;
+		priv->rx_skb_dma[entry] = 0;
+
+		if (has_error) {
+			if (status & RX_DESC_CRC_ERR)
+				priv->stats.rx_crc_errors ++;
+			kfree_skb(skb);
+		} else {
+			pkt_len = (status & RX_DESC_VDBC) - 4; /* Omit the four octet CRC from the length. */
+			if (pkt_len > 1518) {
+				printk(KERN_WARNING "%s: Bogus packet size of %d (%#x).\n", dev->name, pkt_len, pkt_len);
+				pkt_len = 1518;
+				priv->stats.rx_length_errors ++;
+			}
+
+			ast_ether_rx_csum(skb, &priv->rx_desc[entry]);
+			skb_put(skb, pkt_len); /* reflect the DMA operation result */
+			skb->protocol = eth_type_trans(skb, dev);
+
+#ifdef CONFIG_ASTMAC100_NAPI
+			netif_receive_skb(skb);
+#else
+			netif_rx(skb);
+#endif
+	
+			dev->last_rx = jiffies;
+			priv->stats.rx_packets ++;
+			priv->stats.rx_bytes += pkt_len;
+		}
+
+		priv->cur_rx ++;
+	}
+	
+#ifdef BROADCAST_BLACKLIST
+	if(ast_ether_bc[priv->idx].trans_busy_1 == 1){
+		reg_value = inl(ioaddr + AST_ETHER_IER);
+		reg_value |= ISR_RXBUF_UNAVA ;
+		outl(reg_value, ioaddr + AST_ETHER_IER);
+	}
+
+	if(ast_ether_bc[priv->idx].trans_busy_2 == 1){
+		reg_value = inl(ioaddr + AST_ETHER_IER);
+		reg_value |= ISR_RPKT_LOST ;
+		outl(reg_value, ioaddr + AST_ETHER_IER);
+	} 
+#endif
+}
+
+#ifdef CONFIG_ASTMAC100_NAPI
+static int ast_ether_poll(struct napi_struct *napi,int budget)
+{
+       struct ast_ether_priv *priv = container_of(napi, struct ast_ether_priv, napi);
+       struct net_device *dev = priv->dev;
+       unsigned int tmp = 0;
+       int i = 0;
+
+       for(i=0;i<budget;i++) {
+               ast_ether_rx(dev);
+               ast_ether_realloc_rx_buf(dev);
+       }
+       napi_complete(napi);
+       tmp = inl( dev->base_addr + AST_ETHER_IER );
+       outl((tmp | ISR_RPKT2B), dev->base_addr + AST_ETHER_IER);
+       return 0;
+}
+#endif
+
+static irqreturn_t ast_ether_irq_handler(int irq, void *dev_id)
+{
+	struct net_device *dev;
+	struct ast_ether_priv *priv;
+	unsigned int ioaddr;
+	unsigned int intr_mask;
+	unsigned int status;
+	unsigned int reg_value;
+
+	dev = (struct net_device *)dev_id;
+	priv = netdev_priv(dev);
+	ioaddr = dev->base_addr;
+
+	intr_mask = inl(ioaddr + AST_ETHER_IER);
+	status = inl(ioaddr + AST_ETHER_ISR) & intr_mask;
+	outl(status, ioaddr + AST_ETHER_ISR); /* write to clear */
+
+	if (status & ISR_PHYSTS_CHG) { /* PHY status change */
+		printk("ISR_PHYSTS_CHG\n");
+	}
+
+	if (status & ISR_RPKT2B) { /* Rx completed */
+#ifdef CONFIG_ASTMAC100_NAPI
+		outl (intr_mask & ~(ISR_RPKT2B), ioaddr + AST_ETHER_IER);
+		if (likely(napi_schedule_prep(&priv->napi))) 
+			__napi_schedule(&priv->napi);
+#else
+		ast_ether_rx(dev);
+		ast_ether_realloc_rx_buf(dev);
+#endif
+	}
+
+	if (status & ISR_RXBUF_UNAVA){
+		reg_value = inl(ioaddr + AST_ETHER_IER);
+		reg_value &= ~(ISR_RXBUF_UNAVA);
+		outl(reg_value, ioaddr + AST_ETHER_IER);
+#ifdef BROADCAST_BLACKLIST
+		ast_ether_bc[priv->idx].trans_busy_1 = 1 ;
+#endif
+	}
+	if (status & ISR_RPKT_LOST){
+		reg_value = inl(ioaddr + AST_ETHER_IER);
+		reg_value &= ~(ISR_RPKT_LOST);
+		outl(reg_value, ioaddr + AST_ETHER_IER);
+#ifdef BROADCAST_BLACKLIST
+		ast_ether_bc[priv->idx].trans_busy_2 = 1 ;
+#endif
+	}
+	if (status & ISR_TPKT2E) { /* Tx completed */
+		priv->stats.tx_packets ++;
+		ast_ether_free_tx_buf(dev);
+	}
+
+	if (status & ISR_TPKT_LOST)
+		printk("ISR_TPKT_LOST\n");
+
+	if (status & ISR_AHB_ERR)
+		printk("AHB error\n");
+
+	return IRQ_HANDLED;
+}
+
+/* The kernel calls this function when someone wants to use the net_device, typically "ifconfig eth%d up". */
+static int ast_ether_open(struct net_device *dev)
+{
+	int err;
+	int dev_id;
+	struct ast_ether_priv *priv;
+
+	dev_id = dev->dev_id;
+
+	err = request_irq(dev->irq, ast_ether_irq_handler, IRQF_DISABLED, dev->name, dev);
+	if (err != 0) {
+		return err;
+    }
+
+	ast_ether_read_phy_id(dev);
+	ast_ether_set_link_status(dev);
+
+	ast_ether_init_descriptor(dev);
+	ast_ether_up(dev);
+
+	netif_start_queue(dev);
+
+
+    priv = netdev_priv(dev);
+#ifdef CONFIG_ASTMAC100_NAPI
+       napi_enable(&priv->napi); 
+#endif
+    priv->supports_gmii = ast_mii_check_gmii_support(dev);
+	return 0;
+}
+
+static int ast_ether_close(struct net_device *dev)
+{
+	int dev_id;
+	struct ast_ether_priv *priv;
+    unsigned long flags;
+
+	dev_id = dev->dev_id;
+	priv = netdev_priv(dev);
+
+#ifdef CONFIG_ASTMAC100_NAPI
+       napi_disable(&priv->napi);
+#endif
+	netif_stop_queue(dev);
+
+	ast_ether_down(dev->base_addr);
+
+	if (priv->timer.function != NULL)
+	    del_timer_sync(&priv->timer);
+	
+	init_timer(&priv->timer);
+	priv->timer.data = (unsigned long)dev;
+	priv->timer.function = ast_ether_phy_status_checker;
+	priv->timer.expires = jiffies + (AST_PHY_STATUS_CHECK_INTERVAL * HZ);
+	add_timer(&priv->timer);
+
+#ifdef BROADCAST_BLACKLIST
+	if( ast_ether_bc[priv->idx].timer.function != NULL )
+		del_timer_sync(&ast_ether_bc[priv->idx].timer);
+#endif
+
+	free_irq(dev->irq, dev);
+	spin_lock_irqsave(&priv->lock, flags);
+
+	ast_ether_free_rx_buf(dev);
+	ast_ether_free_tx_buf(dev);
+
+	spin_unlock_irqrestore(&priv->lock, flags);
+
+	return 0;
+}
+
+/* Called by the kernel to send a packet out into the void of the net. */
+static void ast_ether_timeout(struct net_device *dev)
+{
+	/* If we get here, some higher level has decided we are broken.
+	There should really be a "kick me" function call instead. */
+	printk(KERN_WARNING "%s: transmit timed out\n", dev->name);
+
+	/* "kick" the adaptor */
+	ast_ether_up(dev);
+
+	netif_wake_queue(dev);
+	dev->trans_start = jiffies;
+}
+
+static struct net_device_stats* ast_ether_get_stats(struct net_device *dev)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+
+	return &priv->stats;
+}
+#ifdef HAVE_MULTICAST
+static void ast_ether_set_multicast_list(struct net_device *dev)
+{
+	unsigned int ioaddr = dev->base_addr;
+	struct ast_ether_priv *priv = netdev_priv(dev);
+#if 1
+	struct dev_mc_list *cur_addr;
+	struct netdev_hw_addr* ha;
+//	char* baddr;
+#endif
+	spin_lock(&priv->lock);
+
+	priv->maccr &= ~(MACCR_RX_ALLADR | MACCR_RX_MULTIPKT_EN | MACCR_RX_MULTIPKT_EN);
+
+	if (dev->flags & IFF_PROMISC) {
+		priv->maccr |= MACCR_RX_ALLADR;
+	} else if (dev->flags & IFF_ALLMULTI) {
+		priv->maccr |= MACCR_RX_MULTIPKT_EN;
+	} 
+
+	if (netdev_mc_count(dev) && (dev->flags & IFF_MULTICAST)) {
+		priv->maccr |= MACCR_RX_HT_EN;
+
+		netdev_for_each_mc_addr(ha, dev) {
+//			baddr = ha->baddr;
+		}
+#if 0
+		for (cur_addr = dev->mc.list; cur_addr != NULL; cur_addr = cur_addr->next) {
+			/* use invert of bits[7:2] of ethernet crc(little endian) result as hash table index */
+			bit_nr = (~ether_crc_le(ETH_ALEN, cur_addr->dmi_addr) & 0x000000fc) >> 2;
+			hash_table[bit_nr >> 5] |= 1 << (bit_nr & 0x1f);
+		}
+#endif
+	}
+
+	/* set the hash table to filter out unwanted multicast packets before they take up memory. */
+//	outl(hash_table[0], ioaddr + AST_ETHER_MAHT0);
+//	outl(hash_table[1], ioaddr + AST_ETHER_MAHT1);
+
+	outl(priv->maccr, ioaddr + AST_ETHER_MACCR);
+	spin_unlock(&priv->lock);
+}
+#else
+
+static void ast_ether_set_multicast_list(struct net_device *dev)
+{
+	unsigned int ioaddr = dev->base_addr;
+	struct ast_ether_priv *priv = netdev_priv(dev);
+
+	if (dev->flags & IFF_PROMISC) {
+		priv->maccr |= MACCR_RX_ALLADR;
+	} else if (dev->flags & IFF_ALLMULTI) {
+		priv->maccr |= MACCR_RX_MULTIPKT_EN;
+	} 
+	outl(priv->maccr, ioaddr + AST_ETHER_MACCR);
+}	
+#endif
+
+int ast_ether_change_mtu(struct net_device *dev, int new_mtu)
+{//frame size shouldn't bigger than MAC capability
+#if defined(CONFIG_SOC_AST2500) || defined(CONFIG_SOC_AST2400)
+	if (new_mtu < 68 || new_mtu > MAX_MTU_SIZE)
+#else
+	if (new_mtu < 68)
+#endif
+		return -EINVAL;
+	dev->mtu = new_mtu;
+	return 0;
+}
+
+static int ast_ether_get_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+    struct ast_ether_priv *priv = netdev_priv(dev);
+	uint32_t advert, bmcr, lpa, nego;
+	uint32_t advert2 = 0, bmcr2 = 0, lpa2 = 0;
+
+	//ast_ether_read_phy_id(dev);
+	
+	cmd->phy_address = 0;
+	cmd->supported = (SUPPORTED_10baseT_Half | SUPPORTED_10baseT_Full | SUPPORTED_100baseT_Half | SUPPORTED_100baseT_Full |
+	     				SUPPORTED_Autoneg | SUPPORTED_TP | SUPPORTED_MII | SUPPORTED_Pause);
+	if (priv->supports_gmii)
+	    cmd->supported |= SUPPORTED_1000baseT_Full;   /* Only support 1G full-duplex in ast2400 */
+	                  
+	cmd->transceiver = XCVR_INTERNAL; /* only supports internal transceiver */
+	cmd->advertising = ADVERTISED_TP | ADVERTISED_MII;
+	advert = ast_ether_phy_read_register(dev, priv->phy_addr, MII_ADVERTISE);
+    if (priv->supports_gmii)
+        advert2 = ast_ether_phy_read_register(dev, priv->phy_addr, MII_CTRL1000);
+
+	if (advert & ADVERTISE_10HALF)
+		cmd->advertising |= ADVERTISED_10baseT_Half;
+	if (advert & ADVERTISE_10FULL)
+		cmd->advertising |= ADVERTISED_10baseT_Full;
+	if (advert & ADVERTISE_100HALF)
+		cmd->advertising |= ADVERTISED_100baseT_Half;
+	if (advert & ADVERTISE_100FULL)
+		cmd->advertising |= ADVERTISED_100baseT_Full;
+	if (advert2 & ADVERTISE_1000FULL)
+		cmd->advertising |= ADVERTISED_1000baseT_Full;
+			
+	bmcr = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMCR);
+	lpa = ast_ether_phy_read_register(dev, priv->phy_addr, MII_LPA);
+    if (priv->supports_gmii) {
+        bmcr2 = ast_ether_phy_read_register(dev, priv->phy_addr, MII_CTRL1000);
+        lpa2 = ast_ether_phy_read_register(dev, priv->phy_addr, MII_STAT1000);
+    }
+	if (bmcr & BMCR_ANENABLE) {
+		cmd->autoneg = AUTONEG_ENABLE;
+		cmd->advertising |= ADVERTISED_Autoneg;
+		if (advert & ADVERTISE_PAUSE_CAP)
+			cmd->advertising |= ADVERTISED_Pause;
+		if (advert & ADVERTISE_PAUSE_ASYM)
+			cmd->advertising |= ADVERTISED_Asym_Pause;
+		nego = mii_nway_result(advert & lpa);
+
+        if ((bmcr2 & (ADVERTISE_1000HALF | ADVERTISE_1000FULL)) &
+		    (lpa2 >> 2))
+			cmd->speed = SPEED_1000;
+            
+		else if (nego == LPA_100FULL || nego == LPA_100HALF)
+			cmd->speed = SPEED_100;
+		else if (nego == LPA_10FULL || nego == LPA_10HALF)
+			cmd->speed = SPEED_10;
+		else
+			cmd->speed = 0;
+
+        if ((lpa2 & LPA_1000FULL) || nego == LPA_100FULL ||
+            nego == LPA_10FULL) 
+			cmd->duplex = DUPLEX_FULL;
+		else if(nego == LPA_100HALF || nego == LPA_10HALF)
+			cmd->duplex = DUPLEX_HALF;
+		else
+			cmd->duplex = 255;
+	} else {
+		cmd->autoneg = AUTONEG_DISABLE;
+
+        cmd->speed = ((bmcr & BMCR_SPEED1000 &&
+            (bmcr & BMCR_SPEED100) == 0) ? SPEED_1000 :
+                (bmcr & BMCR_SPEED100) ? SPEED_100 : SPEED_10);
+		cmd->duplex = (bmcr & BMCR_FULLDPLX) ? DUPLEX_FULL : DUPLEX_HALF;
+	}
+
+	/*RTL8211F has display issue on duplex,here use a way like aspeed sdk 4.06 which use static value to store status */
+	if((priv->phy_oui == REALTEK_RTL82X1X_OUI) && (priv->phy_model == 0x11 ) && (priv->phy_rev == 0x06))
+		cmd->duplex = ast_ether_duplex[priv->idx];	
+
+	return 0;
+}
+
+static int ast_ether_set_settings(struct net_device *dev, struct ethtool_cmd *cmd)
+{
+    struct ast_ether_priv *priv = netdev_priv(dev);
+	uint32_t bmcr, advert, tmp;
+	uint32_t advert2 = 0, tmp2 = 0;
+	int bmcr_status_retry = 0;
+
+	ast_ether_read_phy_id(dev);
+
+	if(priv->phy_oui == 0)
+		return 0;/* not supported PHY or NC-SI */
+
+	ast_ether_phy_write_register(dev, priv->phy_addr, MII_BMCR, BMCR_RESET);
+
+	bmcr = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMCR);
+	while((bmcr & BMCR_RESET) && bmcr_status_retry < 10 )
+	{
+		bmcr = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMCR);
+		bmcr_status_retry++;
+		mdelay(1);
+	}	
+
+	if (cmd->speed != SPEED_10 && cmd->speed != SPEED_100 && cmd->speed != SPEED_1000)
+	{
+		ast_ether_enable_expand_regs_and_clk(dev);
+		return -EINVAL;
+	}
+	if (cmd->duplex != DUPLEX_HALF && cmd->duplex != DUPLEX_FULL)
+	{
+		ast_ether_enable_expand_regs_and_clk(dev);
+		return -EINVAL;
+	}
+	if (cmd->autoneg != AUTONEG_DISABLE && cmd->autoneg != AUTONEG_ENABLE)
+	{
+		ast_ether_enable_expand_regs_and_clk(dev);
+		return -EINVAL;
+	}
+
+	if (cmd->autoneg == AUTONEG_ENABLE) {
+		if ((cmd->advertising & (ADVERTISED_10baseT_Half | 
+                                 ADVERTISED_10baseT_Full | 
+                                 ADVERTISED_100baseT_Half |
+                                 ADVERTISED_100baseT_Full | 
+                                 ADVERTISED_1000baseT_Half | 
+                                 ADVERTISED_1000baseT_Full)) == 0)
+		{
+			ast_ether_enable_expand_regs_and_clk(dev);
+			return -EINVAL;
+		}
+
+		/* advertise only what has been requested */
+		advert = ast_ether_phy_read_register(dev, priv->phy_addr, MII_ADVERTISE);
+		tmp = advert & ~(ADVERTISE_ALL | ADVERTISE_100BASE4);
+		
+        if (priv->supports_gmii) {
+			advert2 = ast_ether_phy_read_register(dev, priv->phy_addr, MII_CTRL1000);
+			tmp2 = advert2 & ~(ADVERTISE_1000HALF | ADVERTISE_1000FULL);
+		}
+		
+		if (cmd->advertising & ADVERTISED_10baseT_Half)
+			tmp |= ADVERTISE_10HALF;
+		if (cmd->advertising & ADVERTISED_10baseT_Full)
+			tmp |= ADVERTISE_10FULL;
+		if (cmd->advertising & ADVERTISED_100baseT_Half)
+			tmp |= ADVERTISE_100HALF;
+		if (cmd->advertising & ADVERTISED_100baseT_Full)
+			tmp |= ADVERTISE_100FULL;
+		if (priv->supports_gmii) {
+			if (cmd->advertising & ADVERTISED_1000baseT_Half)
+                tmp2 |= ADVERTISE_1000HALF;
+			if (cmd->advertising & ADVERTISED_1000baseT_Full)
+				tmp2 |= ADVERTISE_1000FULL;
+		}
+		tmp &= ~ADVERTISE_PAUSE_CAP;
+		tmp &= ~ADVERTISE_PAUSE_ASYM;
+		
+		if (cmd->advertising & ADVERTISED_Pause)
+		{			
+			tmp |= ADVERTISE_PAUSE_CAP;
+		}			
+		if (cmd->advertising & ADVERTISED_Asym_Pause)
+		{			
+			tmp |= ADVERTISE_PAUSE_ASYM;
+		}			
+
+		if (advert != tmp) {
+			ast_ether_phy_write_register(dev, priv->phy_addr, MII_ADVERTISE, tmp);
+		}
+		mdelay(1);
+		if ((priv->supports_gmii) && (advert2 != tmp2))
+			ast_ether_phy_write_register(dev, priv->phy_addr, MII_CTRL1000, tmp2);
+		
+		mdelay(1);
+		/* turn on auto negotiation, and force a re-negotiate */
+		bmcr = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMCR);
+		bmcr |= (BMCR_ANENABLE | BMCR_ANRESTART);
+		ast_ether_phy_write_register(dev, priv->phy_addr, MII_BMCR, bmcr);
+		mdelay(1);
+	} else {
+        if ((cmd->speed == SPEED_1000) && (cmd->duplex == DUPLEX_HALF)) /* not supported */
+        {
+        	ast_ether_enable_expand_regs_and_clk(dev);
+			return -EINVAL;
+        }
+		/* turn off auto negotiation, set speed and duplexity */
+		bmcr = ast_ether_phy_read_register(dev, priv->phy_addr, MII_BMCR);
+		tmp = bmcr & ~(BMCR_ANENABLE | BMCR_SPEED100 |
+			       BMCR_SPEED1000 | BMCR_FULLDPLX);
+
+        if (cmd->speed == SPEED_1000) {
+            tmp |= BMCR_SPEED1000;
+            tmp |= (BMCR_ANENABLE | BMCR_ANRESTART);  /* Don't know why connection lost if auto negotiation is off */
+        } else if (cmd->speed == SPEED_100)
+			tmp |= BMCR_SPEED100;
+		if (cmd->duplex == DUPLEX_FULL)
+			tmp |= BMCR_FULLDPLX;
+		if (bmcr != tmp)
+			ast_ether_phy_write_register(dev, priv->phy_addr, MII_BMCR, tmp);
+		mdelay(1);
+	}
+
+	ast_ether_duplex[priv->idx]= cmd->duplex;
+
+	ast_ether_enable_expand_regs_and_clk(dev);
+
+	return 0;
+}
+static void ast_ether_get_pauseparam(struct net_device *dev,
+		                                 struct ethtool_pauseparam *pause)
+{
+#if AST_PAUSE_FR_ENABLE	
+	struct ethtool_cmd ecmd;
+	memset (&ecmd, 0 , sizeof (struct ethtool_cmd));
+
+	ast_ether_get_settings(dev, &ecmd);
+	pause->autoneg  = ecmd.autoneg;
+
+	if (ecmd.advertising & ADVERTISED_Asym_Pause)
+	{		
+		if (ecmd.advertising & ADVERTISED_Pause)			
+		{			
+			pause->rx_pause = 1;
+			pause->tx_pause = 0;
+		}			
+		else
+		{			
+			pause->rx_pause = 0;
+			pause->tx_pause = 1;
+		}			
+
+	}		
+	else if (ecmd.advertising & ADVERTISED_Pause)
+	{		
+		pause->rx_pause = 1;
+		pause->tx_pause = 1;
+	}		
+	else
+	{
+		pause->rx_pause = 0;
+		pause->tx_pause = 0;
+	}
+#endif			
+}
+
+
+static int ast_ether_set_pauseparam(struct net_device *dev,
+		                                struct ethtool_pauseparam *pause)
+{
+#if AST_PAUSE_FR_ENABLE	
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	struct ethtool_cmd ecmd;
+	u32 advert = 0, tmp;
+	unsigned int reg_value=0;
+	unsigned int ioaddr;
+
+	ioaddr = dev->base_addr;
+	reg_value = inl(ioaddr + AST_ETHER_FCR);
+	memset (&ecmd, 0 , sizeof (struct ethtool_cmd));
+	ast_ether_get_settings(dev, &ecmd);
+	if (ecmd.duplex == DUPLEX_FULL)		
+	{
+		advert = ast_ether_phy_read_register(dev, priv->phy_addr, MII_ADVERTISE);
+		tmp=advert;
+		if (pause->rx_pause)
+		{			
+			if(pause->tx_pause)
+			{	
+				ecmd.advertising |= ADVERTISED_Pause;
+				ecmd.advertising &= ~ADVERTISED_Asym_Pause;
+				ast_ether_set_settings (dev, &ecmd);
+				reg_value |= 0x05;
+			}			
+			else
+			{
+				tmp |= ADVERTISE_PAUSE_CAP;
+	                        tmp |= ADVERTISE_PAUSE_ASYM;
+				reg_value |= 0x01;
+				reg_value &= ~0x04;
+			}
+		}			
+		else if (pause->tx_pause)
+		{
+			tmp &= ~ADVERTISE_PAUSE_CAP;
+	                tmp |= ADVERTISE_PAUSE_ASYM;
+			reg_value |= 0x05;
+		}			
+		else
+		{
+			ecmd.advertising &= ~ADVERTISED_Pause;
+			ecmd.advertising &= ~ADVERTISED_Asym_Pause;
+			ast_ether_set_settings (dev, &ecmd);
+			reg_value &= ~0x05;
+		}			
+		outl(reg_value, ioaddr + AST_ETHER_FCR);
+		if (advert != tmp) {
+			ast_ether_phy_write_register(dev, priv->phy_addr, MII_ADVERTISE, tmp);
+		}
+	}	
+#endif	
+	return 0;			
+}	
+
+static const char main_strings[][ETH_GSTRING_LEN] = {
+	"rx_packets","tx_packets","rx_bytes","tx_bytes","rx_errors",
+	"tx_errors","rx_dropped","tx_dropped","multicast","collisions",
+	"rx_length_errors","rx_over_errors","rx_crc_errors",
+	"rx_frame_errors","rx_fifo_errors","rx_missed_errors",
+	"tx_aborted_errors","tx_carrier_errors","tx_fifo_errors",
+	"tx_heartbeat_errors","tx_window_errors","rx_compressed","tx_compressed"
+};
+static void ast_ether_get_strings(struct net_device *dev,
+				uint32_t stringset, uint8_t *data)
+{
+	int i=0;
+	switch (stringset) {
+	case ETH_SS_STATS:
+		for (i = 0; i < NUM_MAIN_STATS; i++)
+			strcpy(data + i * ETH_GSTRING_LEN,main_strings[i]);
+		break;
+	}
+}
+
+static int ast_ether_get_sset_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return NUM_MAIN_STATS;
+
+	default:
+		return -EOPNOTSUPP;
+	}	
+}
+static void ast_ether_get_ethtool_stats (struct net_device *dev,
+				  struct ethtool_stats *estats, u64 *data)
+{
+	struct ast_ether_priv *priv = netdev_priv(dev);
+	int i=0,index=0;
+	for (i = 0; i < NUM_MAIN_STATS; i++)
+		data[index++] =
+			((unsigned long *) &priv->stats)[i];
+}
+
+static const struct ethtool_ops ast_ether_ethtool_ops = {
+	.get_settings = ast_ether_get_settings,
+	.set_settings = ast_ether_set_settings,
+	.get_link = ethtool_op_get_link,
+	.get_strings = ast_ether_get_strings,
+	.get_sset_count = ast_ether_get_sset_count,
+	.get_ethtool_stats	= ast_ether_get_ethtool_stats,
+ 	.set_pauseparam = ast_ether_set_pauseparam,
+	.get_pauseparam = ast_ether_get_pauseparam,
+};
+
+static const struct net_device_ops ast_netdev_ops = {
+	ndo_open:		ast_ether_open,
+	ndo_stop:		ast_ether_close,
+	ndo_start_xmit:		ast_ether_tx,
+	ndo_tx_timeout:		ast_ether_timeout,
+	ndo_get_stats:		ast_ether_get_stats,
+#ifdef  HAVE_MULTICAST
+	ndo_set_multicast_list:ast_ether_set_multicast_list,
+#else	
+	ndo_set_rx_mode:	ast_ether_set_multicast_list,
+#endif
+	ndo_set_mac_address:	eth_mac_addr,
+	ndo_change_mtu:		ast_ether_change_mtu,
+};
+
+static int ast_ether_init_one(int id)
+{
+	struct net_device *dev;
+	struct ast_ether_priv *priv;
+	int err;
+
+	ast_ether_netdev[id] = NULL;
+	ast_ether_duplex[id] = 0;
+
+	/* alloc_etherdev ensures aligned and zeroed private structures */
+	dev = alloc_etherdev(sizeof(struct ast_ether_priv));
+	if (!dev)
+		return -ENOMEM;
+
+	if (!request_mem_region(ast_ether_phys_base[id], AST_ETHER_IO_REG_SIZE, "ast_ether")) {
+		err = -EBUSY;
+		goto out_alloc_etherdev;
+	}
+
+	dev->base_addr = (unsigned long)ioremap(ast_ether_phys_base[id], AST_ETHER_IO_REG_SIZE);
+	if (!dev->base_addr) {
+		err = -ENOMEM;
+		goto out_release_mem_region;
+	}
+
+	dev->irq = ast_ether_irq[id];
+	IRQ_SET_HIGH_LEVEL(dev->irq);
+	IRQ_SET_LEVEL_TRIGGER(dev->irq);
+
+	dev->dev_id = 0;
+
+	dev->netdev_ops = &ast_netdev_ops;
+
+	dev->hw_features |= NETIF_F_SG;
+	dev->hw_features |= NETIF_F_IP_CSUM; /* Also enable Tx checksum offload */
+	dev->features |= dev->hw_features;
+
+	err = register_netdev(dev);
+	if (err != 0) {
+		goto out_iomap;
+	}
+
+	ether_setup(dev); /* Fill in the fields of the device structure with ethernet values. */
+	SET_ETHTOOL_OPS(dev, &ast_ether_ethtool_ops);
+	/*
+	 * initialize private data structure 'priv'
+	 * it is zeroed and aligned in alloc_etherdev
+	 */
+	priv = netdev_priv(dev);
+
+	priv->idx = id;
+   priv->old_speed = 0xFF;//Init to unknow speed
+   priv->old_duplex = 0xFF;//Init to unknow Duplex
+	ast_ether_get_hardware_addr(dev);
+
+#ifdef CONFIG_ASTMAC100_NAPI
+	priv->dev = dev;
+	netif_napi_add(dev, &priv->napi, ast_ether_poll, 4);
+#endif
+
+	spin_lock_init(&priv->lock);
+	spin_lock_init(&priv->mii_lock);
+
+	priv->maccr = MACCR_CRC_APD | MACCR_RXMAC_EN | MACCR_TXMAC_EN | MACCR_RXDMA_EN | MACCR_TXDMA_EN | MACCR_RX_BROADPKT_EN | MACCR_RX_MULTIPKT_EN | MACCR_RX_RUNT;
+
+	ast_ether_alloc_descriptor(dev);
+	priv->link_state = -1;
+
+	ast_ether_netdev[id] = dev;
+	return 0;
+
+out_iomap:
+	iounmap((void *) dev->base_addr);
+out_release_mem_region:
+	release_mem_region(ast_ether_phys_base[id], AST_ETHER_IO_REG_SIZE);
+out_alloc_etherdev:
+	free_netdev(dev);
+
+	return err;
+}
+
+#define AST_SCU_CLK_STOP_MAC2            0x00200000 /* bit 21 */
+#define AST_SCU_CLK_STOP_MAC1            0x00100000 /* bit 20 */
+
+#define AST_SCU_RESET_MAC2               0x00001000 /* bit 12 */
+#define AST_SCU_RESET_MAC1               0x00000800 /* bit 11 */
+
+#define AST_SCU_SET_MAC1_MULTI_PIN       0xC0000000
+#define AST_SCU_SET_MAC2_MULTI_PIN       0x00000004
+#define AST_SCU_UNLOCK_MAGIC             0x1688A8A8
+
+void __init ast_ether_set_multipin(void)
+{
+	uint32_t reg;
+
+	iowrite32(AST_SCU_UNLOCK_MAGIC, (void * __iomem)SCU_KEY_CONTROL_REG); /* unlock SCU */
+
+	/* Enable MAC1 Multi-function pin for AST in its SCU Multi function pin register */
+	reg = ioread32((void * __iomem)SCU_MULTI_FN_PIN_3);
+	reg |= AST_SCU_SET_MAC1_MULTI_PIN;
+	iowrite32(reg, (void * __iomem)SCU_MULTI_FN_PIN_3);
+
+	/* Enable MAC2 Multi-function pin for AST in its SCU Multi function pin register */
+	//reg = ioread32((void * __iomem)SCU_MULTI_FN_PIN_5);
+	//reg |= AST_SCU_SET_MAC2_MULTI_PIN;
+	//iowrite32(reg, (void * __iomem)SCU_MULTI_FN_PIN_5);
+
+	iowrite32(0, (void * __iomem)SCU_KEY_CONTROL_REG); /* lock SCU */
+
+	return;
+}
+
+void __init ast_ether_scu_init(void)
+{
+	uint32_t reg;
+
+	outl(AST_SCU_UNLOCK_MAGIC, SCU_KEY_CONTROL_REG); /* unlock SCU */
+
+	/* enable clcok */
+	reg = inl(SCU_CLK_STOP_REG);
+	reg &= ~(AST_SCU_CLK_STOP_MAC1 | AST_SCU_CLK_STOP_MAC2);
+	outl(reg, SCU_CLK_STOP_REG);
+
+	mdelay(10);
+
+	/* stop the reset */
+	reg = inl(SCU_SYS_RESET_REG);
+	reg &= ~(AST_SCU_RESET_MAC1 | AST_SCU_RESET_MAC2);
+	outl(reg, SCU_SYS_RESET_REG);
+
+	mdelay(10);
+
+	outl(0, SCU_KEY_CONTROL_REG); /* lock SCU */
+}
+
+int __init ast_ether_init(void)
+{
+	int result, id;
+
+	ast_ether_scu_init();
+	ast_ether_set_multipin();
+
+	result = -ENODEV;
+
+	for (id = 0; id < AST_ETHER_USE_NUM; id ++) {
+		if (ast_ether_init_one(id) == 0)
+			result = 0;
+	}
+	return result;
+}
+
+void ast_ether_exit(void)
+{
+	int id;
+	struct ast_ether_priv *priv;
+
+	for (id = 0; id < AST_ETHER_USE_NUM; id ++) {
+		if (ast_ether_netdev[id] == NULL)
+			continue;
+
+		priv = netdev_priv(ast_ether_netdev[id]);
+		if(priv->timer.function != NULL)
+			del_timer_sync(&priv->timer);
+		if (priv->rx_desc)
+			dma_free_coherent(NULL, sizeof(struct ast_eth_desc) * RX_DES_NUM, priv->rx_desc, priv->rx_desc_dma);
+		if (priv->tx_desc)
+			dma_free_coherent(NULL, sizeof(struct ast_eth_desc) * TX_DES_NUM, priv->tx_desc, priv->tx_desc_dma);
+
+		iounmap((void *) ast_ether_netdev[id]->base_addr);
+		release_mem_region(ast_ether_phys_base[id], AST_ETHER_IO_REG_SIZE);
+
+		unregister_netdev(ast_ether_netdev[id]);
+		free_netdev(ast_ether_netdev[id]);
+		ast_ether_netdev[id] = NULL;
+	}
+}
+
+module_init(ast_ether_init);
+module_exit(ast_ether_exit);
+
+MODULE_AUTHOR("American Megatrends Inc.");
+MODULE_DESCRIPTION("AST2050/AST2100/AST2150/AST2200/AST2300/AST2400 Ethernet MAC driver");
+MODULE_LICENSE("GPL");
