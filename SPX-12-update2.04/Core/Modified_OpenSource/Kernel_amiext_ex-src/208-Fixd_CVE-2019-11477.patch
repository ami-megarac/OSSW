diff -Naur linux_org/include/linux/tcp.h linux/include/linux/tcp.h
--- linux_org/include/linux/tcp.h	2019-07-10 14:05:40.269806509 +0800
+++ linux/include/linux/tcp.h	2019-07-10 14:08:52.140163737 +0800
@@ -391,4 +391,7 @@
 	return 0;
 }
 
+int tcp_skb_shift(struct sk_buff *to, struct sk_buff *from, int pcount,
+		  int shiftlen);
+
 #endif	/* _LINUX_TCP_H */
diff -Naur linux_org/include/net/tcp.h linux/include/net/tcp.h
--- linux_org/include/net/tcp.h	2019-07-10 14:05:46.001553919 +0800
+++ linux/include/net/tcp.h	2019-07-10 14:09:20.549665882 +0800
@@ -54,6 +54,8 @@
 
 #define MAX_TCP_HEADER	(128 + MAX_HEADER)
 #define MAX_TCP_OPTION_SPACE 40
+#define TCP_MIN_SND_MSS		48
+#define TCP_MIN_GSO_SIZE	(TCP_MIN_SND_MSS - MAX_TCP_OPTION_SPACE)
 
 /* 
  * Never offer a window over 32767 without using window scaling. Some
diff -Naur linux_org/net/ipv4/tcp.c linux/net/ipv4/tcp.c
--- linux_org/net/ipv4/tcp.c	2019-07-10 14:05:51.321319504 +0800
+++ linux/net/ipv4/tcp.c	2019-07-10 14:10:13.634322343 +0800
@@ -3165,6 +3165,7 @@
 	int max_rshare, max_wshare, cnt;
 	unsigned int i;
 
+	BUILD_BUG_ON(TCP_MIN_SND_MSS <= MAX_TCP_OPTION_SPACE);
 	BUILD_BUG_ON(sizeof(struct tcp_skb_cb) > sizeof(skb->cb));
 
 	percpu_counter_init(&tcp_sockets_allocated, 0);
diff -Naur linux_org/net/ipv4/tcp_input.c linux/net/ipv4/tcp_input.c
--- linux_org/net/ipv4/tcp_input.c	2019-07-10 14:10:36.056800327 +0800
+++ linux/net/ipv4/tcp_input.c	2019-07-10 14:14:34.482283897 +0800
@@ -1319,7 +1319,7 @@
 	TCP_SKB_CB(skb)->seq += shifted;
 
 	skb_shinfo(prev)->gso_segs += pcount;
-	BUG_ON(skb_shinfo(skb)->gso_segs < pcount);
+	WARN_ON_ONCE(tcp_skb_pcount(skb) < pcount);
 	skb_shinfo(skb)->gso_segs -= pcount;
 
 	/* When we're adding to gso_segs == 1, gso_size will be zero,
@@ -1385,6 +1385,21 @@
 	return !skb_headlen(skb) && skb_is_nonlinear(skb);
 }
 
+int tcp_skb_shift(struct sk_buff *to, struct sk_buff *from,
+		  int pcount, int shiftlen)
+{
+	/* TCP min gso_size is 8 bytes (TCP_MIN_GSO_SIZE)
+	 * Since TCP_SKB_CB(skb)->tcp_gso_segs is 16 bits, we need
+	 * to make sure not storing more than 65535 * 8 bytes per skb,
+	 * even if current MSS is bigger.
+	 */
+	if (unlikely(to->len + shiftlen >= 65535 * TCP_MIN_GSO_SIZE))
+		return 0;
+	if (unlikely(tcp_skb_pcount(to) + pcount > 65535))
+		return 0;
+	return skb_shift(to, from, shiftlen);
+}
+
 /* Try collapsing SACK blocks spanning across multiple skbs to a single
  * skb.
  */
@@ -1489,8 +1504,8 @@
 	/* tcp_sacktag_one() won't SACK-tag ranges below snd_una */
 	if (!after(TCP_SKB_CB(skb)->seq + len, tp->snd_una))
 		goto fallback;
-
-	if (!skb_shift(prev, skb, len))
+	
+	if (!tcp_skb_shift(prev, skb, pcount, len))
 		goto fallback;
 	if (!tcp_shifted_skb(sk, skb, state, pcount, len, mss, dup_sack))
 		goto out;
@@ -1509,10 +1524,9 @@
 		goto out;
 
 	len = skb->len;
-	if (skb_shift(prev, skb, len)) {
-		pcount += tcp_skb_pcount(skb);
-		tcp_shifted_skb(sk, skb, state, tcp_skb_pcount(skb), len, mss, 0);
-	}
+	pcount = tcp_skb_pcount(skb);
+	if (tcp_skb_shift(prev, skb, pcount, len))
+		tcp_shifted_skb(sk, skb, state, pcount, len, mss, 0);
 
 out:
 	state->fack_count += pcount;
diff -Naur linux_org/net/ipv4/tcp_output.c linux/net/ipv4/tcp_output.c
--- linux_org/net/ipv4/tcp_output.c	2019-07-10 14:06:02.036847387 +0800
+++ linux/net/ipv4/tcp_output.c	2019-07-10 14:14:54.224408969 +0800
@@ -1249,8 +1249,8 @@
 	mss_now -= icsk->icsk_ext_hdr_len;
 
 	/* Then reserve room for full set of TCP options and 8 bytes of data */
-	if (mss_now < 48)
-		mss_now = 48;
+	if (mss_now < TCP_MIN_SND_MSS)
+		mss_now = TCP_MIN_SND_MSS;
 	return mss_now;
 }
 
