diff -Naur linux_org/fs/bio.c linux/fs/bio.c
--- linux_org/fs/bio.c	2019-04-08 14:13:50.354022940 +0800
+++ linux/fs/bio.c	2019-04-08 14:17:08.711642793 +0800
@@ -1269,7 +1269,8 @@
 	struct bio *bio;
 	int cur_page = 0;
 	int ret, offset;
-
+	struct bio_vec *bvec;
+	
 	for (i = 0; i < iov_count; i++) {
 		unsigned long uaddr = (unsigned long)iov[i].iov_base;
 		unsigned long len = iov[i].iov_len;
@@ -1312,7 +1313,12 @@
 
 		ret = get_user_pages_fast(uaddr, local_nr_pages,
 				write_to_vm, &pages[cur_page]);
-		if (ret < local_nr_pages) {
+		if (unlikely(ret < local_nr_pages)) {
+			for (j = cur_page; j < page_limit; j++) {
+				if (!pages[j])
+					break;
+				put_page(pages[j]);
+			}			
 			ret = -EFAULT;
 			goto out_unmap;
 		}
@@ -1320,7 +1326,8 @@
 		offset = uaddr & ~PAGE_MASK;
 		for (j = cur_page; j < page_limit; j++) {
 			unsigned int bytes = PAGE_SIZE - offset;
-
+			unsigned short prev_bi_vcnt = bio->bi_vcnt;
+			
 			if (len <= 0)
 				break;
 			
@@ -1334,6 +1341,13 @@
 					    bytes)
 				break;
 
+			/*
+			 * check if vector was merged with previous
+			 * drop page reference if needed
+			 */
+			if (bio->bi_vcnt == prev_bi_vcnt)
+				put_page(pages[j]);				
+				
 			len -= bytes;
 			offset = 0;
 		}
@@ -1359,10 +1373,8 @@
 	return bio;
 
  out_unmap:
-	for (i = 0; i < nr_pages; i++) {
-		if(!pages[i])
-			break;
-		page_cache_release(pages[i]);
+	bio_for_each_segment_all(bvec, bio, i) {
+		page_cache_release(bvec->bv_page);
 	}
  out:
 	kfree(pages);
